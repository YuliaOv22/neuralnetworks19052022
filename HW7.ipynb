{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW7",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grWCtrSjTt-_"
      },
      "source": [
        "# **Практическое задание**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Сделайте краткий обзор любой архитектуры для object detection. Проведите анализ: чем\n",
        "отличается выбранная вами архитектура нейронной сети от других? В чём плюсы и\n",
        "минусы данной архитектуры? Какие могут возникнуть трудности при применении этой\n",
        "архитектуры на практике?\n",
        "2. *Ссылка на репозиторий с полным кодом для обучения ssd нейросети:\n",
        "https://github.com/sergeyveneckiy/ssd-tensorflow. Попробуйте улучшить точность её работы и напишите отчёт (что вы пробовали изменить в её параметрах и как это\n",
        "отражалось на процессе обучения нейронной сети). Обратите внимание! Мин. сист. требования для запуска данного проекта — минимум 8 Gb ОЗУ. Если у вас\n",
        "недостаточно мощности компьютера, просто изучите содержимое исходного кода и датасета данного проекта\n"
      ],
      "metadata": {
        "id": "FX1ujlOM5Avm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Существуют следующие архитектуры для Object Detection:**\n",
        "**1986/2005**\n",
        "1. HOG (Histogram of Oriented Gradients) - Robert K. McConnell/Navneet Dalal, Bill Triggs\n",
        "**2014**\n",
        "1. R-CNN (Region-based Convolutional Neural Networks) - Ross Girshik\n",
        "**2015**\n",
        "1. SSD (Single Shot Detector) - Wei Liu\n",
        "2. Fast R-CNN - Ross Girshick\n",
        "3. SPP-net (Spatial Pyramid Pooling) - Kaiming He\n",
        "4. YOLO (You Only Look Once) - Joseph Redmon\n",
        "**2016**\n",
        "1. Faster R-CNN - Kaiming He, Ross Girshick\n",
        "2. R-FCN (Region-based Fully Convolutional Network) - Kaiming He\n",
        "3. YOLOv2 (YOLO9000: Better, Faster, Stronger) - Joseph Redmon, Ali Farhadi\n",
        "4. SqueezeDet (Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving) - Bichen Wu\n",
        "**2017**\n",
        "1. Mask R-CNN - Kaiming He\n",
        "2. Cascade R-CNN (Delving into High Quality Object Detection) - Zhaowei Cai\n",
        "3. RetinaNet (Focal Loss for Dense Object Detection) - Tsung-Yi Lin\n",
        "4. MobileNets (Efficient Convolutional Neural Networks for Mobile Vision Applications) - Menglong Zhu\n",
        "5. RefineDet (Single-Shot Refinement Neural Network for Object Detection) - Shifeng Zhang\n",
        "6. RON (Reverse Connection with Objectness Prior Networks for Object Detection) - Anbang Yao\n",
        "7. DSSD (Deconvolutional Single Shot Detector) - Cheng-Yang Fu\n",
        "**2018**\n",
        "1. YOLOv3 (An Incremental Improvement) - Joseph Redmon, Ali Farhadi\n",
        "2. CornerNet (Detecting Objects as Paired Keypoints) - Hei Law, Jia Deng\n",
        "**2019**\n",
        "1. Trident Net (Scale-Aware Trident Networks for Object Detection) - Yuntao Chen\n",
        "2. CenterNet (Keypoint Triplets for Object Detection) - Kaiwen Duan\n",
        "3. EffcientNet (Rethinking Model Scaling for Convolutional Neural Networks) - Mingxing Tan, Quoc V. Le\n",
        "**2020**\n",
        "1. YOLOv4 (Optimal Speed and Accuracy of Object Detection) - Alexey Bochkovskiy\n",
        "2. D2Det (Towards High Quality Object Detection and Instance Segmentation) - Jiale Cao\n",
        "3. Sparse R-CNN (End-to-End Object Detection with Learnable Proposals) - Peize Sun\n",
        "4. CentripetalNet (Pursuing High-quality Keypoint Pairs for Object Detection) - Guoxuan Li\n",
        "5. YOLOv5 - Glenn Jocher\n",
        "**2021**\n",
        "1. YOLOR (You Only Learn One Representation: Unified Network for Multiple Tasks) - Chien-Yao Wang\n",
        "2. GRCNN (Graph Recognition Convolutional Neural Network for Synthesizing Programs from Flow Charts) - Lin Cheng\n",
        "\n"
      ],
      "metadata": {
        "id": "hba0-cz65NAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **YOLOR**\n",
        "Рассмотрим одну из самых современных моделей детектирования объектов - YOLOR.\n",
        "\n",
        "Авторы: Chien-Yao Wang, I-Hau Yeh, Hong-Yuan Mark Liao.\n",
        "\n",
        "Место: Institute of Information Science, Academia Sinica, Тайвань.\n",
        "\n",
        "Год: 2021.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "YOLOR - это архитектура модели, которая может кодировать явные и неявные знания (признаки) в одном и том же представлении. При этом явное знание извлекается из грубых деталей изображения, получаемых в неглубоких слоях. Неявное знание фокусируется на более мелких деталях и соответствует более глубоким слоям. Объединив оба вида признаков, YOLOR может быстро и точно обнаруживать мелкие детали на фотографиях высокой четкости.\n",
        "\n",
        "![image.png](https://blog.paperspace.com/content/images/size/w1000/2022/04/Screen-Shot-2022-04-26-at-5.42.53-PM.png)\n",
        "\n",
        "**Явные знания** извлекаются из метаданных или баз данных изображений, которые либо тщательно аннотированы, либо хорошо организованы. После анализа таких данных модель хорошо разбирается в классификации изображений. Явное знание прямо соответствует наблюдениям, которые предполагается предсказать.\n",
        "\n",
        "**Неявные знания** получаются с помощью признаков в глубоких слоях, которые не соответствуют наблюдениям. Для получения таких знаний используют неявные нейронные представления и модели глубокого равновесия.\n",
        "\n",
        "**Эффективность**. YOLOR является одним из самых быстрых алгоритмов обнаружения объектов в современном компьютерном зрении. На наборе данных MS COCO средняя средняя точность YOLOR на 3,8% выше по сравнению с PP-YOLOv2 при той же скорости вывода, и такая же точность по сравнению с Scaled YOLOv4 при скорости вывода на 88% больше.\n",
        "\n",
        "![image.png](https://viso.ai/wp-content/uploads/2021/08/yolor-vs-yolov4-performance-comparison-1060x664.png)\n",
        "\n",
        "\n",
        "Благодаря объединению явных и неявных признаков, модель может не только обнаружить объект на изображении, но и ответить на дополнительные вопросы. \n",
        "![image.png](https://miro.medium.com/max/1400/0*LjTA0M06RFfAmVMN)\n",
        "\n",
        "\n",
        "**Преимущества работы**.\n",
        " - Очень быстро детектирует объекты. \n",
        " - Можно использовать в режиме реального времени (например на видео с YouTube).\n",
        " - Можно извлекать дополнительную информацию из изображения.\n",
        "\n",
        "**Трудности работы**.\n",
        " - Для работы с моделью необходима предварительная обработка данных (например датасета COCO).\n",
        " - Требуются большие ресурсы, в том числе временные, для собственной тренировки модели. \n",
        "\n"
      ],
      "metadata": {
        "id": "OYb9bqe5Jyvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Источники:**\n",
        "\n",
        "https://arxiv.org/abs/2003.09119\n",
        "\n",
        "https://neptune.ai/blog/object-detection-algorithms-and-libraries\n",
        "\n",
        "https://viso.ai/deep-learning/object-detection/ \n",
        "\n",
        "https://www.scirp.org/journal/paperinformation.aspx?paperid=115011\n",
        "\n",
        "https://www.v7labs.com/blog/object-detection-guide\n",
        "\n",
        "https://viso.ai/deep-learning/yolor/\n",
        "\n",
        "https://blog.paperspace.com/yolor/\n",
        "\n",
        "https://arxiv.org/pdf/2105.04206v1.pdf"
      ],
      "metadata": {
        "id": "cm1pt0H4EmkL"
      }
    }
  ]
}